MASTER RECORD ‚Äî Memory System (What we built)
Files & roles

utils/logger.py
Centralized append-only logging for:

chat_log.txt ‚Äî human-readable rolling transcript (all sessions, appended).

chat_log.json ‚Äî structured log of sessions [ { timestamp, messages, summary } ].

session_summaries.txt ‚Äî appended structured summaries per session.

utils/memory.py

Conversation helpers: init_history, add_message, trim_history.

Retrieval (initial JSON-based + ‚Äúbare-bones‚Äù summaries-based):

load_memory() ‚Äî reads chat_logs/chat_log.json to list of sessions.

retrieve_from_memory(query, section=None, limit=3)
Current ‚Äúbare-bones‚Äù version reads session_summaries.txt, finds substring matches, returns short excerpts.

controller.py

Executes Orchestrator‚Äôs planned steps.

Logging hooks:

_send_to_main_chat() calls append_txt(history) after each model reply ‚Üí keeps chat_log.txt fresh.

finalize_session(history) (called on exit/quit) generates a structured summary with summary_bot, appends it to:

session_summaries.txt

chat_log.json via append_json_with_summary(history, summary_text)

Memory actions (when enabled):

_query_memory(details) ‚Üí uses utils.memory.retrieve_from_memory and stores last result in self.last_memory so _send_to_main_chat() can inject it into the main bot‚Äôs prompt.

_update_memory(details) ‚Üí minimal key/value store in self.memory[section] = data (placeholder for future persistence).

orchestrator.py

Strict JSON-only planner with regex cleaning for safety:

SYSTEM_PROMPT enforces: first char {, last }, no prose, always end with a communication step.

plan(user_input):

Calls Gemini (temperature=0) ‚Üí extracts JSON block ‚Üí json.loads or falls back to clarify_context.

Supported actions in the schema (all planned, not executed here):

send_to_main_chat, query_memory, update_memory, summarize_session, web_search, analyze_data, generate_plan, clarify_context, run_code, idle.

main.py

Wires everything.

Critical order: add user input to history before calling Orchestrator ‚Üí Controller.

On exit: controller.finalize_session(history) ‚Üí writes summaries + JSON.

Exact data formats
history (in-memory during a run)
[
  {"role": "user",  "parts": ["...user text..."]},
  {"role": "model", "parts": ["...model reply..."]},
  ...
]

chat_logs/chat_log.json
[
  {
    "timestamp": "[YYYY-MM-DD HH:MM:SS]",
    "messages": [
      {"role": "user", "parts": ["Hi"]},
      {"role": "model", "parts": ["Hello!"]}
    ],
    "summary": "üïí Session Timestamp: ...\nüß© Session Context:\n‚Ä¢ ..."
  },
  ...
]

chat_logs/chat_log.txt
=== Session Start [YYYY-MM-DD HH:MM:SS] ===

User: ...
Model: ...

=== Session End ===

chat_logs/session_summaries.txt
=== Summary (YYYY-MM-DD HH:MM:SS) ===
üïí Session Timestamp: ...
üß© Session Context:
‚Ä¢ ...
‚úÖ Actions Taken:
‚Ä¢ ...
...
----------------------------------------------------------------------

Functions ‚Äî Full inventory & behavior
utils/logger.py

timestamp() ‚Üí "[YYYY-MM-DD HH:MM:SS]"

append_txt(history)
Appends one entire session to chat_log.txt (called repeatedly from _send_to_main_chat() so transcript stays fresh; also fine to run again at end).

append_json(history)
Appends a session without summary (not used after we added end-of-session summarization).

append_json_with_summary(history, summary_text)
Appends { timestamp, messages, summary } to chat_log.json. Creates file if absent.

_append_to_json_file(session_data)
Private helper; loads existing JSON array, appends, writes back.

utils/memory.py

init_history(), add_message(history, role, text), trim_history(history, max_turns)

load_memory() ‚Üí returns list from chat_log.json (or [] if missing/invalid).

retrieve_from_memory(query, section=None, limit=3) ‚Äî current bare-bones version:

Reads session_summaries.txt.

Finds query occurrences, returns up to limit excerpts with ¬±200 chars context.

Returns [{"timestamp": None, "match": "..."}] with No matching memory if none found.

(Earlier, we also had a JSON-based search version that scanned chat_log.json text blobs; we replaced it with the ultra-reliable summaries-only search at your request.)

controller.py

execute_plan(plan, history, user_input="")

Guards plan end: if no final communication step, auto-append a send_to_main_chat.

Dispatches each step:

send_to_main_chat ‚Üí _send_to_main_chat(details, history, user_input)

summarize_session ‚Üí _summarize_session(details, history)

query_memory ‚Üí _query_memory(details)

update_memory ‚Üí _update_memory(details)

web_search ‚Üí _web_search(details) (placeholder string)

clarify_context / idle ‚Üí short strings

_send_to_main_chat(details, history, user_input)

Important fix: Sends the actual user_input (not just the orchestrator‚Äôs topic string) + optional self.last_memory if present.

Prompts the main bot for a 1‚Äì3 sentence reply; logs with append_txt.

_summarize_session(details, history)

Summarizes history using summary_bot with scope+format.

_query_memory(details)

Calls retrieve_from_memory(query, section) and stores a copy of the joined matches in self.last_memory so _send_to_main_chat can include it.

_update_memory(details)

In-memory dict update: self.memory[section] = data (placeholder for future persistence).

_web_search(details)

Placeholder string for future integration.

finalize_session(history)

Builds a structured summary using summary_bot.

Appends to session_summaries.txt.

Calls append_json_with_summary(history, summary_text) to update chat_log.json.

orchestrator.py

Strict JSON planner with cleaning:

SYSTEM_PROMPT: action schema + Output Policy (no prose, {‚Ä¶} only, final communication step required).

plan(user_input):

generate_content with temperature: 0 (optionally random_seed: 0).

Cleans code fences, extracts first {...} block, parses to dict.

Fallback ‚Üí clarify_context if parse fails.





Things that are for later:
1. Memory thingy.
2. Web search.